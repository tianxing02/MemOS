user_id: "root"
chat_model:
  backend: "huggingface"
  config:
    model_name_or_path: "Qwen/Qwen3-1.7B"
    temperature: 0.1
    remove_think_prefix: true
    max_tokens: 4096
mem_reader:
  backend: "simple_struct"
  config:
    llm:
      backend: "ollama"
      config:
        model_name_or_path: "qwen3:0.6b"
        remove_think_prefix: true
        temperature: 0.8
        max_tokens: 1024
        top_p: 0.9
        top_k: 50
    embedder:
      backend: "ollama"
      config:
        model_name_or_path: "nomic-embed-text:latest"
    chunker:
      backend: "sentence"
      config:
        tokenizer_or_token_counter: "gpt2"
        chunk_size: 512
        chunk_overlap: 128
        min_sentences_per_chunk: 1
mem_scheduler:
  backend: "general_scheduler"
  config:
    top_k: 10
    act_mem_update_interval: 30
    context_window_size: 10
    thread_pool_max_workers: 10
    consume_interval_seconds: 1
    working_mem_monitor_capacity: 20
    activation_mem_monitor_capacity: 5
    enable_parallel_dispatch: true
    enable_activation_memory: true
max_turns_window: 20
top_k: 5
enable_textual_memory: true
enable_activation_memory: true
enable_parametric_memory: false
enable_mem_scheduler: true
